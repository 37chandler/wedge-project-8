{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Building Summary Tables\n",
    "It is useful to have summary files that allow you to quickly answer questions such as the following:\n",
    "\n",
    "How have our sales-by-day changed over the last few months?\n",
    "What is our most popular item in each department?\n",
    "Which owners spend the most per month in each department?\n",
    "The classic way to structure data to answer these questions is in a relational database. In this task, you will build the summary text files that hold this data and populate a relational database with the data.\n",
    "\n",
    "Input\n",
    "You will process your owner records in GBQ to build the summary tables.\n",
    "\n",
    "Output\n",
    "For this task, you will build a single SQLite database via Python (in a .db file) containing three tables:\n",
    "\n",
    "Sales by date by hour: By calendar date (YYYY-MM-DD) and hour of the day, determine the total spend in the store, the number of transactions, and a count of the number of items[1].\n",
    "Sales by owner by year by month: A file that has the following columns: card_no, year, month, sales, transactions, and items.\n",
    "Sales by product description by year by month: A file that has the following columns: upc, description, department number, department name, year, month, sales, transactions, and items.\n",
    "You will submit your Python code that builds the database.\n",
    "\n",
    "You are welcome to generate these tables via queries in Google Big Query, export the text files, and store them locally on your machine. Then you will need to write a Python script that creates the database, creates the tables, and fills those tables. Obviously, it’d be great to do the whole thing in Python.\n",
    "\n",
    "[1] We can identify the number of items by looking for trans_status of ‘’ or ‘ ‘ (blank string or a single space). To be completely correct you would want to remove Returns (R) and Voids (V) as well. I’ll give you a query that helps with this.\n",
    "\n",
    "Deliverable\n",
    "The Python code that creates the summary tables. The Python code that builds the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Summary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How have our sales-by-day changed over the last few months?  \n",
    "What is our most popular item in each department?  \n",
    "Which owners spend the most per month in each department?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### careful\n",
    "-- wrong table--- fail to query entire dataset\n",
    "-- wrong queries \n",
    "-- off by 10 - 20 let it go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import re\n",
    "#import datetime \n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import pandas_gbq\n",
    "#import janitor\n",
    "\n",
    "# Do our imports for the code\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# These first two values will be different on your machine. \n",
    "service_path = \"/Users/chandler/Dropbox/Teaching/\"\n",
    "service_file = 'umt-msba-037daf11ee16.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'umt-msba' # change this to your project. \n",
    "\n",
    "# And this should stay the same. \n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pass in our credentials so that Python has permission to access our project.\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally we establish our connection\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)\n",
    "\n",
    "# Set up a client\n",
    "#client = bigquery.Client(project = \"umt-msba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\npleg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\auth\\_default.py:76: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client(project = \"umt-msba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table 1\n",
    "Sales by date by hour: By calendar date (YYYY-MM-DD) and hour of the day, determine the total spend in the store, the number of transactions, and a count of the number of items[1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\npleg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sales        date  hour  transactioins  items\n",
      "0   441.82  2015-01-01     8             18    116\n",
      "1  1501.09  2015-01-01     9             51    394\n",
      "2  3715.39  2015-01-01    10             87    884\n",
      "3  4166.61  2015-01-01    11            128   1100\n",
      "4  4982.26  2015-01-01    12            165   1328\n"
     ]
    }
   ],
   "source": [
    "query_1 = \"\"\"\n",
    "    SELECT ROUND(SUM(total), 2) as sales\n",
    "        , EXTRACT(DATE FROM datetime) AS date\n",
    "        , EXTRACT(HOUR FROM datetime) AS hour\n",
    "        , COUNT(DISTINCT CONCAT(\n",
    "            CAST(EXTRACT(DATE FROM datetime) AS STRING), \n",
    "            CAST(register_no AS STRING), \n",
    "            CAST(emp_no AS STRING), \n",
    "            CAST(trans_no AS STRING)\n",
    "            )) AS transactioins\n",
    "\n",
    "        ,SUM(\n",
    "            CASE\n",
    "            WHEN trans_status IN ('V', 'R') THEN -1\n",
    "            ELSE 1\n",
    "        END\n",
    "        ) AS items\n",
    "\n",
    "        FROM `umt-msba.wedge_transactions.transArchive*`\n",
    "        WHERE department NOT IN (0, 15)\n",
    "        AND (trans_status IS NULL \n",
    "        OR trans_status IN ('V', 'R', '', ' '))\n",
    "        AND datetime BETWEEN TIMESTAMP('2015-01-01') AND TIMESTAMP('2015-07-01')\n",
    "        GROUP BY date, hour\n",
    "        ORDER BY date, hour;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "try:\n",
    "    query_job = client.query(query_1)  # Start the query job\n",
    "    df1 = query_job.to_dataframe()  # Convert the result to a pandas DataFrame\n",
    "\n",
    "    # View the DataFrame\n",
    "    print(df1.head())  # Show the first 5 rows of the DataFrame\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table 2\n",
    "Sales by owner by year by month: A file that has the following columns: card_no, year, month, sales, transactions, and items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to check if there are other owner numbers that need to be excluded like 3????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\npleg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     owner  year  month   sales  transactions  items\n",
      "0  10000.0  2015      1   23.86             1     11\n",
      "1  10000.0  2015      2  123.47             3     44\n",
      "2  10000.0  2015      3   72.93             3     21\n",
      "3  10000.0  2015      4  123.88             4     47\n",
      "4  10000.0  2015      5   67.75             1     26\n"
     ]
    }
   ],
   "source": [
    "query_2 = \"\"\"\n",
    "    SELECT DISTINCT card_no as owner\n",
    "        , EXTRACT(YEAR FROM datetime) AS year\n",
    "        , EXTRACT(MONTH FROM datetime) AS month\n",
    "        , ROUND(SUM(total), 2) as sales\n",
    "        , COUNT(DISTINCT CONCAT(\n",
    "            CAST(EXTRACT(DATE FROM datetime) AS STRING), \n",
    "            CAST(register_no AS STRING), \n",
    "            CAST(emp_no AS STRING), \n",
    "            CAST(trans_no AS STRING)\n",
    "            )) AS transactions\n",
    "        ,SUM(\n",
    "            CASE\n",
    "            WHEN trans_status IN ('V', 'R') THEN -1\n",
    "            ELSE 1\n",
    "        END\n",
    "        ) AS items\n",
    "\n",
    "    FROM `umt-msba.wedge_transactions.transArchive*`\n",
    "    WHERE department NOT IN (0, 15)\n",
    "    AND card_no != 3\n",
    "    AND (trans_status IS NULL \n",
    "    OR trans_status IN ('V', 'R', '', ' '))\n",
    "    AND datetime BETWEEN TIMESTAMP('2015-01-01') AND TIMESTAMP('2015-07-01')\n",
    "    GROUP BY owner, year, month\n",
    "    ORDER BY owner, year, month;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "try:\n",
    "    query_job = client.query(query_2)  # Start the query job\n",
    "    df2 = query_job.to_dataframe()  # Convert the result to a pandas DataFrame\n",
    "\n",
    "    # View the DataFrame\n",
    "    print(df2.head())  # Show the first 5 rows of the DataFrame\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table 3\n",
    "Sales by product description by year by month: A file that has the following columns: upc, description, department number, department name, year, month, sales, transactions, and items.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\npleg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\cloud\\bigquery\\table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       upc  description  department number department name  year  month  \\\n",
      "0  0.01DP2      PRODUCE                2.0         PRODUCE  2015      1   \n",
      "1  0.01DP3  BULK Coupon                3.0            BULK  2015      2   \n",
      "2  0.01DP4  REF GROCERY                4.0     REF GROCERY  2015      2   \n",
      "3  0.01DP4  REF GROCERY                4.0     REF GROCERY  2015      4   \n",
      "4  0.01DP4  REF GROCERY                4.0     REF GROCERY  2015      5   \n",
      "\n",
      "   sales  transactions  items  \n",
      "0   0.00             1      0  \n",
      "1   0.01             1     -1  \n",
      "2   0.00             1      0  \n",
      "3   0.00             2      0  \n",
      "4   0.00             2      0  \n"
     ]
    }
   ],
   "source": [
    "query_3 = \"\"\"\n",
    "    SELECT DISTINCT upc\n",
    "    , description\n",
    "    , trans.department AS `department number`\n",
    "    , depts.dept_name AS `department name`\n",
    "    , EXTRACT(YEAR FROM datetime) AS year\n",
    "    , EXTRACT(MONTH FROM datetime) AS month\n",
    "    , ROUND(SUM(total), 2) as sales\n",
    "    , COUNT(DISTINCT CONCAT(\n",
    "        CAST(EXTRACT(DATE FROM datetime) AS STRING), \n",
    "        CAST(register_no AS STRING), \n",
    "        CAST(emp_no AS STRING), \n",
    "        CAST(trans_no AS STRING)\n",
    "        )) AS transactions\n",
    "    ,SUM(\n",
    "        CASE\n",
    "        WHEN trans_status IN ('V', 'R') THEN -1\n",
    "        ELSE 1\n",
    "    END\n",
    "    ) AS items\n",
    "\n",
    "    FROM `umt-msba.wedge_transactions.transArchive*` as trans\n",
    "    JOIN `umt-msba.wedge_transactions.department_lookup` as depts\n",
    "    ON trans.department = depts.department\n",
    "    WHERE trans.department NOT IN (0, 15)\n",
    "    AND card_no != 3\n",
    "    AND (trans_status IS NULL \n",
    "    OR trans_status IN ('V', 'R', '', ' '))\n",
    "    AND datetime BETWEEN TIMESTAMP('2015-01-01') AND TIMESTAMP('2015-07-01')\n",
    "    GROUP BY upc, description, `department number`, `department name`, year, month\n",
    "    ORDER BY upc, description, `department number`, `department name`, year, month;\n",
    "    \"\"\"\n",
    "# Execute the query\n",
    "try:\n",
    "    query_job = client.query(query_3)  # Start the query job\n",
    "    df3 = query_job.to_dataframe()  # Convert the result to a pandas DataFrame\n",
    "\n",
    "    # View the DataFrame\n",
    "    print(df3.head())  # Show the first 5 rows of the DataFrame\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Query failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SQLite Database and Add Summary Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to the SQLite database (or create it)\n",
    "conn = sqlite3.connect('summary_database.db')\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create table summary table 1\n",
    "df1.to_sql('summary_table_1', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Create table summary table 2\n",
    "df2.to_sql('summary_table_2', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Create table summary table 3\n",
    "df3.to_sql('summary_table_3', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check to Make Sure Data is In Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(441.82, '2015-01-01', 8, 18, 116), (1501.09, '2015-01-01', 9, 51, 394), (3715.39, '2015-01-01', 10, 87, 884), (4166.61, '2015-01-01', 11, 128, 1100), (4982.26, '2015-01-01', 12, 165, 1328)]\n",
      "[(10000.0, 2015, 1, 23.86, 1, 11), (10000.0, 2015, 2, 123.47, 3, 44), (10000.0, 2015, 3, 72.93, 3, 21), (10000.0, 2015, 4, 123.88, 4, 47), (10000.0, 2015, 5, 67.75, 1, 26)]\n",
      "[('0.01DP2', 'PRODUCE', 2.0, 'PRODUCE', 2015, 1, 0.0, 1, 0), ('0.01DP3', 'BULK Coupon', 3.0, 'BULK', 2015, 2, 0.01, 1, -1), ('0.01DP4', 'REF GROCERY', 4.0, 'REF GROCERY', 2015, 2, 0.0, 1, 0), ('0.01DP4', 'REF GROCERY', 4.0, 'REF GROCERY', 2015, 4, 0.0, 2, 0), ('0.01DP4', 'REF GROCERY', 4.0, 'REF GROCERY', 2015, 5, 0.0, 2, 0)]\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('summary_database.db')\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query to check the first summary table\n",
    "cursor.execute(\"SELECT * FROM summary_table_1 LIMIT 5\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "cursor.execute(\"SELECT * FROM summary_table_2 LIMIT 5\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "cursor.execute(\"SELECT * FROM summary_table_3 LIMIT 5\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "# Commit and close the connection when done\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
